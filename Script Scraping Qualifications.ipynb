{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Docs\\HV\\ProcesosSelección\\Trascender 2023\\Script Scraping Qualifications.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Docs/HV/ProcesosSelecci%C3%B3n/Trascender%202023/Script%20Scraping%20Qualifications.ipynb#W0sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m soup \u001b[39m=\u001b[39m bs(datos\u001b[39m.\u001b[39mtext, \u001b[39m\"\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Docs/HV/ProcesosSelecci%C3%B3n/Trascender%202023/Script%20Scraping%20Qualifications.ipynb#W0sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m titulo \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39mfind_all(class_\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msc-1318654d-7 fACRye\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Docs/HV/ProcesosSelecci%C3%B3n/Trascender%202023/Script%20Scraping%20Qualifications.ipynb#W0sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(titulo\u001b[39m.\u001b[39;49mtext)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Docs/HV/ProcesosSelecci%C3%B3n/Trascender%202023/Script%20Scraping%20Qualifications.ipynb#W0sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m calificaciones \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39mfind_all(class_\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msc-e3e7b191-0 iKUUVe sc-f1a948e3-3 bQrxup\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Docs/HV/ProcesosSelecci%C3%B3n/Trascender%202023/Script%20Scraping%20Qualifications.ipynb#W0sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Itera a través de los elementos y obtén el texto\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\NICOL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\bs4\\element.py:2428\u001b[0m, in \u001b[0;36mResultSet.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2426\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[0;32m   2427\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 2428\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[0;32m   2429\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mResultSet object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. You\u001b[39m\u001b[39m'\u001b[39m\u001b[39mre probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m key\n\u001b[0;32m   2430\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: ResultSet object has no attribute 'text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "rickymorty = \"https://www.imdb.com/title/tt2861424/episodes\" #Link donde se buscará la información\n",
    "encabezado = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}\n",
    "#Este encabezado puede ser genérico sin embargo hay que indagar si presenta modificaciones según caso de uso\n",
    "\n",
    "datos = requests.get(rickymorty, headers= encabezado)\n",
    "\n",
    "datos2 = html.fromstring(datos.text)\n",
    "soup = bs(datos.text, \"html.parser\")\n",
    "titulo = soup.find_all(class_= \"sc-1318654d-7 fACRye\")\n",
    "calificaciones = soup.find_all(class_=\"sc-e3e7b191-0 iKUUVe sc-f1a948e3-3 bQrxup\")\n",
    "\n",
    "# Itera a través de los elementos y obtén el texto\n",
    "for title, calif in zip(titulo, calificaciones):\n",
    "    #Dividir texto de calificaciones\n",
    "    cap = title.text.split()[0].replace(\".\", \"\")\n",
    "    cap_parts = cap.split(\"E\")\n",
    "    cap_parts[0] = \"S\" + cap_parts[0][1:].zfill(2)  # Agrega \"0\" después de la \"S\" si es necesario\n",
    "    cap_parts[1] = \"E\" + cap_parts[1].zfill(2)  # Rellena con ceros a la izquierda de la E si es necesario\n",
    "    cap = \"\".join(cap_parts)\n",
    "    stars = calif.text.split()[0]\n",
    "    votes = calif.text.split(\"(\", 1)[1].split(\")\")[0]\n",
    "\n",
    "\n",
    "    capituloycalificación = cap + \"-\" + stars + \"-\" + votes\n",
    "\n",
    "    print(capituloycalificación)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Cap-Seasons   Stars votes\n",
      "0       S01E01  7.9/10   16K\n",
      "1       S01E02  8.7/10   16K\n",
      "2       S01E03  8.3/10   15K\n",
      "3       S01E04  8.6/10   15K\n",
      "4       S01E05  9.0/10   16K\n",
      "5       S01E06  9.0/10   16K\n",
      "6       S01E07  7.9/10   14K\n",
      "7       S01E08  8.7/10   15K\n",
      "8       S01E09  8.4/10   13K\n",
      "9       S01E10  9.3/10   17K\n",
      "10      S01E11  8.4/10   13K\n",
      "11      S02E01  8.8/10   15K\n",
      "12      S02E02  8.8/10   14K\n",
      "13      S02E03  8.5/10   14K\n",
      "14      S02E04  9.5/10   19K\n",
      "15      S02E05  8.2/10   13K\n",
      "16      S02E06  9.3/10   16K\n",
      "17      S02E07  8.4/10   13K\n",
      "18      S02E08  7.6/10   13K\n",
      "19      S02E09  8.5/10   13K\n",
      "20      S02E10  9.3/10   16K\n",
      "21      S03E01  9.6/10   23K\n",
      "22      S03E02  8.1/10   14K\n",
      "23      S03E03  9.3/10   21K\n",
      "24      S03E04  8.1/10   13K\n",
      "25      S03E05  8.4/10   13K\n",
      "26      S03E06  8.8/10   14K\n",
      "27      S03E07  9.8/10   34K\n",
      "28      S03E08  8.9/10   13K\n",
      "29      S03E09  7.9/10   11K\n",
      "30      S03E10  8.2/10   12K\n",
      "31      S04E01  8.9/10   15K\n",
      "32      S04E02  8.2/10   13K\n",
      "33      S04E03  8.3/10   13K\n",
      "34      S04E04  7.3/10   13K\n",
      "35      S04E05  8.8/10   12K\n",
      "36      S04E06  8.0/10   12K\n",
      "37      S04E07  8.0/10  9.8K\n",
      "38      S04E08  9.4/10   15K\n",
      "39      S04E09  7.7/10  9.4K\n",
      "40      S04E10  9.1/10   11K\n",
      "41      S05E01  9.0/10   14K\n",
      "42      S05E02  8.7/10   12K\n",
      "43      S05E03  7.8/10   12K\n",
      "44      S05E04  5.8/10   13K\n",
      "45      S05E05  7.0/10  9.4K\n",
      "46      S05E06  7.1/10  9.2K\n",
      "47      S05E07  6.4/10    9K\n",
      "48      S05E08  8.2/10  9.1K\n",
      "49      S05E09  8.3/10  7.9K\n",
      "50      S05E10  9.3/10   12K\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.imdb.com/title/tt2861424/episodes\"  # URL de la página principal\n",
    "encabezado = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}\n",
    "\n",
    "\n",
    "capituloycalificación = []\n",
    "# Itera a través de las páginas de episodios utilizando el segmento '?season='\n",
    "# Esto sucede porque se está navegando con la etiqueta temporada de la página\n",
    "season_number = 1\n",
    "max_season = 5\n",
    "while season_number <= max_season:\n",
    "    # Construye la URL de la página actual y de navegación horizontal\n",
    "    current_url = f\"{base_url}/?season={season_number}\"\n",
    "\n",
    "    # Realiza una solicitud GET a la página actual\n",
    "    response = requests.get(current_url, headers=encabezado)\n",
    "    soup = bs(response.text, \"html.parser\")\n",
    "\n",
    "    # Encuentra los elementos de título y calificación en la página actual\n",
    "    titulo = soup.find_all(class_=\"sc-1318654d-7 fACRye\")\n",
    "    calificaciones = soup.find_all(class_=\"sc-e3e7b191-0 iKUUVe sc-f1a948e3-3 bQrxup\")\n",
    "\n",
    "    # Si no se encuentran elementos en la página, sal del bucle\n",
    "    if not titulo:\n",
    "        break\n",
    "\n",
    "    # Itera a través de los elementos y obtén el texto\n",
    "    for title, calif in zip(titulo, calificaciones):\n",
    "        # Dividir texto de calificaciones\n",
    "        cap = title.text.split()[0].replace(\".\", \"\") #Acceder al contenido del título, separandolo en espacios y reemplazando el punto entre \n",
    "                                                    #la abreviación y el nombre del título\n",
    "        cap_parts = cap.split(\"E\") #Dividir el texto del capítulo en partes buscando la E\n",
    "        cap_parts[0] = \"S\" + cap_parts[0][1:].zfill(2)  # Agrega \"0\" después de la \"S\" si es necesario\n",
    "        cap_parts[1] = \"E\" + cap_parts[1].zfill(2)  # El split elimina la E así que es necesario agregarlo nuevamente\n",
    "                                                    # Y además Rellena con ceros a la izquierda de la E si es necesario\n",
    "        cap = \"\".join(cap_parts) #Unir en un solo grupo las partes extraidas\n",
    "        stars = calif.text.split()[0] #Acceder a la calificación obtenida a través la plataforma\n",
    "        votes = calif.text.split(\"(\", 1)[1].split(\")\")[0] #Acceder al dato de cantidad de votos obtenidos sin contemplar los paréntesis existentes\n",
    "        capituloycalificación.append((cap, stars, votes))\n",
    "        #print(capituloycalificación)\n",
    "\n",
    "    # Incrementa el número de temporada para pasar a la siguiente página\n",
    "    season_number += 1\n",
    "\n",
    "rating = pd.DataFrame(capituloycalificación, columns=[\"Cap-Seasons\", \"Stars\", \"votes\"])\n",
    "print(rating)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
