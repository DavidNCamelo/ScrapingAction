{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "rickymorty = \"https://www.imdb.com/title/tt2861424/episodes\" #Link donde se buscará la información\n",
    "encabezado = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}\n",
    "#Este encabezado puede ser genérico sin embargo hay que indagar si presenta modificaciones según caso de uso\n",
    "\n",
    "datos = requests.get(rickymorty, headers= encabezado)\n",
    "\n",
    "datos2 = html.fromstring(datos.text)\n",
    "soup = bs(datos.text, \"html.parser\")\n",
    "titulo = soup.find_all(class_= \"sc-9115db22-7 sOSGg\")\n",
    "calificaciones = soup.find_all(class_=\"sc-e3e7b191-0 iKUUVe sc-f1a948e3-3 bQrxup\")\n",
    "\n",
    "# Itera a través de los elementos y obtén el texto\n",
    "for title, calif in zip(titulo, calificaciones):\n",
    "    #Dividir texto de calificaciones\n",
    "    cap = title.text.split()[0].replace(\".\", \"\")\n",
    "    cap_parts = cap.split(\"E\")\n",
    "    cap_parts[0] = \"S\" + cap_parts[0][1:].zfill(2)  # Agrega \"0\" después de la \"S\" si es necesario\n",
    "    cap_parts[1] = \"E\" + cap_parts[1].zfill(2)  # Rellena con ceros a la izquierda de la E si es necesario\n",
    "    cap = \"\".join(cap_parts)\n",
    "    stars = calif.text.split()[0]\n",
    "    votes = calif.text.split(\"(\", 1)[1].split(\")\")[0]\n",
    "\n",
    "\n",
    "    capituloycalificación = cap + \"-\" + stars + \"-\" + votes\n",
    "\n",
    "    print(capituloycalificación)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Cap-Seasons   Stars votes\n",
      "0       S01E01  7.9/10   17K\n",
      "1       S01E02  8.7/10   17K\n",
      "2       S01E03  8.3/10   16K\n",
      "3       S01E04  8.7/10   16K\n",
      "4       S01E05  9.0/10   17K\n",
      "5       S01E06  9.0/10   17K\n",
      "6       S01E07  7.9/10   14K\n",
      "7       S01E08  8.7/10   16K\n",
      "8       S01E09  8.4/10   14K\n",
      "9       S01E10  9.3/10   18K\n",
      "10      S01E11  8.4/10   14K\n",
      "11      S02E01  8.8/10   15K\n",
      "12      S02E02  8.8/10   15K\n",
      "13      S02E03  8.5/10   14K\n",
      "14      S02E04  9.5/10   21K\n",
      "15      S02E05  8.2/10   14K\n",
      "16      S02E06  9.3/10   17K\n",
      "17      S02E07  8.4/10   13K\n",
      "18      S02E08  7.6/10   14K\n",
      "19      S02E09  8.5/10   14K\n",
      "20      S02E10  9.3/10   17K\n",
      "21      S03E01  9.6/10   24K\n",
      "22      S03E02  8.1/10   14K\n",
      "23      S03E03  9.3/10   22K\n",
      "24      S03E04  8.1/10   14K\n",
      "25      S03E05  8.4/10   13K\n",
      "26      S03E06  8.8/10   15K\n",
      "27      S03E07  9.8/10   36K\n",
      "28      S03E08  8.9/10   14K\n",
      "29      S03E09  7.9/10   12K\n",
      "30      S03E10  8.2/10   12K\n",
      "31      S04E01  8.9/10   16K\n",
      "32      S04E02  8.2/10   14K\n",
      "33      S04E03  8.3/10   13K\n",
      "34      S04E04  7.3/10   14K\n",
      "35      S04E05  8.8/10   13K\n",
      "36      S04E06  8.0/10   12K\n",
      "37      S04E07  8.0/10   11K\n",
      "38      S04E08  9.5/10   16K\n",
      "39      S04E09  7.7/10   10K\n",
      "40      S04E10  9.0/10   12K\n",
      "41      S05E01  9.0/10   15K\n",
      "42      S05E02  8.7/10   13K\n",
      "43      S05E03  7.8/10   12K\n",
      "44      S05E04  5.7/10   14K\n",
      "45      S05E05  7.0/10   10K\n",
      "46      S05E06  7.1/10   10K\n",
      "47      S05E07  6.4/10  9.8K\n",
      "48      S05E08  8.2/10  9.9K\n",
      "49      S05E09  8.3/10  8.7K\n",
      "50      S05E10  9.3/10   13K\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.imdb.com/title/tt2861424/episodes\"  # URL de la página principal\n",
    "encabezado = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}\n",
    "\n",
    "capituloycalificación = []\n",
    "# Itera a través de las páginas de episodios utilizando el segmento '?season='\n",
    "# Esto sucede porque se está navegando con la etiqueta temporada de la página\n",
    "season_number = 1\n",
    "max_season = 5\n",
    "while season_number <= max_season:\n",
    "    # Construye la URL de la página actual y de navegación horizontal\n",
    "    current_url = f\"{base_url}/?season={season_number}\"\n",
    "\n",
    "    # Realiza una solicitud GET a la página actual\n",
    "    response = requests.get(current_url, headers=encabezado)\n",
    "    soup = bs(response.text, \"html.parser\")\n",
    "\n",
    "    # Encuentra los elementos de título y calificación en la página actual\n",
    "    titulo = soup.find_all(class_=\"sc-f2169d65-5 dUeItJ\")\n",
    "    calificaciones = soup.find_all(class_=\"sc-e2dbc1a3-0 ajrIH sc-282bae8e-3 bXuGWE\")\n",
    "\n",
    "    # Si no se encuentran elementos en la página, sal del bucle\n",
    "    if not titulo:\n",
    "        break\n",
    "\n",
    "    # Itera a través de los elementos y obtén el texto\n",
    "    for title, calif in zip(titulo, calificaciones):\n",
    "        # Dividir texto de calificaciones\n",
    "        cap = title.text.split()[0].replace(\".\", \"\") #Acceder al contenido del título, separandolo en espacios y reemplazando el punto entre \n",
    "                                                    #la abreviación y el nombre del título\n",
    "        cap_parts = cap.split(\"E\") #Dividir el texto del capítulo en partes buscando la E\n",
    "        cap_parts[0] = \"S\" + cap_parts[0][1:].zfill(2)  # Agrega \"0\" después de la \"S\" si es necesario\n",
    "        cap_parts[1] = \"E\" + cap_parts[1].zfill(2)  # El split elimina la E así que es necesario agregarlo nuevamente\n",
    "                                                    # Y además Rellena con ceros a la izquierda de la E si es necesario\n",
    "        cap = \"\".join(cap_parts) #Unir en un solo grupo las partes extraidas\n",
    "        stars = calif.text.split()[0] #Acceder a la calificación obtenida a través la plataforma\n",
    "        votes = calif.text.split(\"(\", 1)[1].split(\")\")[0] #Acceder al dato de cantidad de votos obtenidos sin contemplar los paréntesis existentes\n",
    "        capituloycalificación.append((cap, stars, votes))\n",
    "        #print(capituloycalificación)\n",
    "\n",
    "    # Incrementa el número de temporada para pasar a la siguiente página\n",
    "    season_number += 1\n",
    "\n",
    "rating = pd.DataFrame(capituloycalificación, columns=[\"Cap-Seasons\", \"Stars\", \"votes\"])\n",
    "print(rating)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
